{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "624fb15c-6f9c-4e47-b497-48418a0a18d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters after: 20,736\n",
      "Generated Answer: Context: The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse ('Norman' comes from 'Norseman') raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia.\n",
      "Question: Who were the Normans descended from?\n",
      "Answer: The Normans were descended from the Norsemen who invaded and conquered the northern parts of Europe in the 10th and 11th\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "from utils import *\n",
    "from trl import SFTTrainer\n",
    "\n",
    "# Step 1: Load the model and tokenizer\n",
    "model_name = \"gpt2-large\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Ensure the tokenizer has a padding token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "# Step 2: Load and preprocess the SQuAD dataset\n",
    "dataset = load_dataset(\"squad\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    contexts = examples['context']\n",
    "    questions = examples['question']\n",
    "    answers = examples['answers']\n",
    "    \n",
    "    prompts = [\n",
    "        f\"Context: {context}\\nQuestion: {question}\\nAnswer:\"\n",
    "        for context, question in zip(contexts, questions)\n",
    "    ]\n",
    "    \n",
    "    targets = [answer['text'][0] for answer in answers]\n",
    "    \n",
    "    return {\n",
    "        \"prompt\": prompts,\n",
    "        \"target\": targets\n",
    "    }\n",
    "\n",
    "tokenized_dataset = dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "\n",
    "model.to(\"cuda\")\n",
    "\n",
    "ltype = \"curlora\"\n",
    "for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, type(model.transformer.h[0].attn)):\n",
    "        if ltype == \"lora\":\n",
    "            module.c_attn = LinearWithLoRA(module.c_attn, 24, 1)\n",
    "        else:\n",
    "            module.c_attn = LinearWithCURLoRA(module.c_attn, 24, 1)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters after: {total_params:,}\")\n",
    "model.to(\"cuda\")\n",
    "\n",
    "def generate_answer(context, question = None):\n",
    "    if question:\n",
    "        prompt = f\"Context: {context}\\nQuestion: {question}\\nAnswer:\"\n",
    "    else:\n",
    "        prompt = context\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens = 25,\n",
    "                            pad_token_id= tokenizer.eos_token_id,\n",
    "                            eos_token_id= tokenizer.eos_token_id)#, num_return_sequences=1, do_sample=True)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "context = \"The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse ('Norman' comes from 'Norseman') raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia.\"\n",
    "question = \"Who were the Normans descended from?\"\n",
    "\n",
    "generated_answer = generate_answer(context, question)\n",
    "print(\"Generated Answer:\", generated_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2711a228-b462-48a8-8472-f11d0cb3dbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Context: The university is the major seat of the Congregation of Holy Cross (albeit not its official headquarters, which are in Rome). Its main seminary, Moreau Seminary, is located on the campus across St. Joseph lake from the Main Building. Old College, the oldest building on campus and located near the shore of St. Mary lake, houses undergraduate seminarians. Retired priests and brothers reside in Fatima House (a former retreat center), Holy Cross House, as well as Columba Hall near the Grotto. The university through the Moreau Seminary has ties to theologian Frederick Buechner. While not Catholic, Buechner has praised writers from Notre Dame and Moreau Seminary created a Buechner Prize for Preaching.\n",
      "Question: What individuals live at Fatima House at Notre Dame?\n",
      "Answer: The house is a residence for retired priests and brothers. It is located on the campus of Notre Dame. The house is a\n"
     ]
    }
   ],
   "source": [
    "generated_answer = generate_answer(tokenized_dataset[\"train\"][13][\"prompt\"])\n",
    "print(\"Generated Answer:\", generated_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a6a788e-20dd-4be8-b66a-c5a46ab064f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Retired priests and brothers'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"train\"][13][\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81020b88-a563-4206-8618-3fafbb31a4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 05:54, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.004200</td>\n",
       "      <td>2.284526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.013800</td>\n",
       "      <td>2.268037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.978800</td>\n",
       "      <td>2.256925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.998500</td>\n",
       "      <td>2.249362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.930700</td>\n",
       "      <td>2.246941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=300, training_loss=3.0027708943684894, metrics={'train_runtime': 355.4773, 'train_samples_per_second': 3.376, 'train_steps_per_second': 0.844, 'total_flos': 916574914669056.0, 'train_loss': 3.0027708943684894, 'epoch': 0.013698786515827807})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    #num_train_epochs=3,\n",
    "    max_steps = 300,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    warmup_steps=30,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    eval_steps=60,\n",
    "    save_steps=120,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2.5e-4,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub = False,\n",
    ")\n",
    "\n",
    "# Step 4: Initialize the SFTTrainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"].select(range(300)),\n",
    "    dataset_text_field=\"prompt\",\n",
    "    max_seq_length=512,\n",
    ")\n",
    "\n",
    "# Step 5: Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "709aef54-3bd4-4bde-921b-55e81879177e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Context: The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse ('Norman' comes from 'Norseman') raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia.\n",
      "Question: Who were the Normans descended from?\n",
      "Answer: The Normans were descended from the Norsemen who invaded and conquered the northern parts of Europe in the 10th and 11th\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Save the fine-tuned model\n",
    "#trainer.save_model(\"./fine_tuned_gpt2_large_squad\")\n",
    "\n",
    "# Step 7: Test the model\n",
    "# Example usage\n",
    "context = \"The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse ('Norman' comes from 'Norseman') raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia.\"\n",
    "question = \"Who were the Normans descended from?\"\n",
    "\n",
    "generated_answer = generate_answer(context, question)\n",
    "print(\"Generated Answer:\", generated_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "847e281d-46f1-4eb2-985f-54ecb9779c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Context: The university is the major seat of the Congregation of Holy Cross (albeit not its official headquarters, which are in Rome). Its main seminary, Moreau Seminary, is located on the campus across St. Joseph lake from the Main Building. Old College, the oldest building on campus and located near the shore of St. Mary lake, houses undergraduate seminarians. Retired priests and brothers reside in Fatima House (a former retreat center), Holy Cross House, as well as Columba Hall near the Grotto. The university through the Moreau Seminary has ties to theologian Frederick Buechner. While not Catholic, Buechner has praised writers from Notre Dame and Moreau Seminary created a Buechner Prize for Preaching.\n",
      "Question: What individuals live at Fatima House at Notre Dame?\n",
      "Answer: The house is a residence for retired priests and brothers. It is located on the campus of Notre Dame. The house is a\n"
     ]
    }
   ],
   "source": [
    "generated_answer = generate_answer(tokenized_dataset[\"train\"][13][\"prompt\"])\n",
    "print(\"Generated Answer:\", generated_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6249cec-f791-42eb-96b2-3607e7956647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Context: After leaving Edison's company Tesla partnered with two businessmen in 1886, Robert Lane and Benjamin Vail, who agreed to finance an electric lighting company in Tesla's name, Tesla Electric Light & Manufacturing. The company installed electrical arc light based illumination systems designed by Tesla and also had designs for dynamo electric machine commutators, the first patents issued to Tesla in the US.\n",
      "Question: What did lane and vail finance?\n",
      "Answer: Tesla Electric Light & Manufacturing was a company that was incorporated in 1887 and was incorporated in 1891. Lane and Vail\n",
      "\n",
      "Actual Answer: Tesla Electric Light & Manufacturing\n"
     ]
    }
   ],
   "source": [
    "generated_answer = generate_answer(tokenized_dataset[\"validation\"][1311][\"prompt\"])\n",
    "print(\"Generated Answer:\", generated_answer)\n",
    "print(\"\\nActual Answer:\", tokenized_dataset[\"validation\"][1311][\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160b2675-879a-459e-b5bd-d76b4b2782c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
