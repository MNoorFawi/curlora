{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e22781c-c04f-49df-8ef2-5f0f835948b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "import os\n",
    "#os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72f97992-0e62-44c2-8fea-5141255b90b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters after: 2,304\n",
      "Perplexity: 28.25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1280)\n",
       "    (wpe): Embedding(1024, 1280)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-35): 36 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): LinearWithCURLoRA(\n",
       "            (linear): Conv1D()\n",
       "            (curlora): CURModule()\n",
       "          )\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1280, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AdamW, get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "import gc\n",
    "import tiktoken\n",
    "from previous_chapters import *\n",
    "\n",
    "model_name = \"gpt2-large\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "ltype = \"curlora\"\n",
    "for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, type(model.transformer.h[0].attn)):\n",
    "        if ltype == \"lora\":\n",
    "            module.c_attn = LinearWithLoRA(module.c_attn, 8, 1)\n",
    "        else:\n",
    "            module.c_attn = LinearWithCURLoRA(module.c_attn, 8, 1)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters after: {total_params:,}\")\n",
    "\n",
    "model.to(device)\n",
    "    \n",
    "ppl = calculate_perplexity(model, tokenizer, txt)\n",
    "print(\"Perplexity:\", round(ppl, 2))\n",
    "    \n",
    "torch.manual_seed(1311)\n",
    "num_classes = 2\n",
    "lm_head = model.lm_head\n",
    "in_features=1280\n",
    "model.lm_head = torch.nn.Linear(in_features=in_features, out_features=num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0906f755-0380-4e60-83d0-6a6f5d5ab417",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cd7e4c0-43fa-4123-b371-b85904b1a4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set up optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(mrpc_dataset[\"train\"])\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=500, num_training_steps=num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32081eca-9f8c-4414-97b2-e71da75ef4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [03:51<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average loss: 0.02003725999184237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [03:58<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average loss: 0.019793559812342456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [03:39<00:00,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average loss: 0.0193952102795032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert to PyTorch datasets\n",
    "train_dataset = mrpc_dataset[\"train\"]\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i in tqdm(range(0, len(train_dataset), batch_size)):\n",
    "        batch = train_dataset[i:i+batch_size]\n",
    "        inputs = tokenizer(batch[\"sentence1\"], batch[\"sentence2\"], return_tensors=\"pt\",\n",
    "                           truncation=True, padding = True, max_length = max_len).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs)[\"logits\"][:, -1, :]#.cpu()\n",
    "        y = torch.LongTensor(batch[\"label\"]).to(device)\n",
    "        loss = torch.nn.functional.cross_entropy(outputs, y)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        torch.cuda.empty_cache()\n",
    "        _ = gc.collect()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Average loss: {total_loss / len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84ce9d9c-9368-4e2a-b898-7c263541f7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on MRPC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 408/408 [02:06<00:00,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRPC Accuracy: 0.7034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating on MRPC...\")\n",
    "mrpc_accuracy = evaluate_mrpc(model, tokenizer, mrpc_dataset, device)\n",
    "print(f\"MRPC Accuracy: {mrpc_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efdd8bfe-00f9-4ac3-bfa1-8b86a8ec5540",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrpc_head = model.lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db4ae15-8b50-4fb3-90a9-af2274771d13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "626155e0-dfd7-4623-87c9-804d295c0c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1311)\n",
    "\n",
    "num_classes = 2\n",
    "model.lm_head = torch.nn.Linear(in_features=in_features, out_features=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "590cd2ae-4788-47d4-bdf7-b53af4a6908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(sst_dataset[\"train\"])\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=500, num_training_steps=num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfd3d57c-48e7-41b8-a143-9a7fd31977d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [03:23<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average loss: 0.001623428777327302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [03:16<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average loss: 0.001548231452516296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [02:52<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average loss: 0.0014444273413506473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert to PyTorch datasets\n",
    "train_dataset = sst_dataset[\"train\"]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i in tqdm(range(0, 5000, batch_size)):\n",
    "        batch = train_dataset[i:i+batch_size]\n",
    "        inputs = tokenizer(batch[\"sentence\"], return_tensors=\"pt\",\n",
    "                           truncation=True, padding = True, max_length = max_len).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs)[\"logits\"][:, -1, :]#.cpu()\n",
    "        y = torch.LongTensor(batch[\"label\"]).to(device)\n",
    "        loss = torch.nn.functional.cross_entropy(outputs, y)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        torch.cuda.empty_cache()\n",
    "        _ = gc.collect()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Average loss: {total_loss / len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2523032d-dbb9-4152-a3b7-3abc878c518e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on SST-2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 872/872 [04:25<00:00,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST-2 Accuracy: 0.7569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating on SST-2...\")\n",
    "accuracy = evaluate_sst2(model, tokenizer, sst_dataset, device)\n",
    "print(f\"SST-2 Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5a59825-5542-4cc0-99dc-f8caed532280",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a2f0246-fbaa-4985-bbd1-9068e7d9db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_head = model.lm_head\n",
    "model.lm_head = mrpc_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62b0d326-74f3-4875-81b2-aee6b40f166a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on MRPC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 408/408 [02:05<00:00,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRPC Accuracy: 0.7059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating on MRPC...\")\n",
    "mrpc_accuracy = evaluate_mrpc(model, tokenizer, mrpc_dataset, device)\n",
    "print(f\"MRPC Accuracy: {mrpc_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fb8b486-8461-4fc9-8451-09f841e9e602",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1311)\n",
    "\n",
    "num_classes = 3\n",
    "model.lm_head = torch.nn.Linear(in_features=in_features, out_features=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c26694b-61c8-425f-9363-fd4f83a8f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "num_epochs = 5\n",
    "num_training_steps = num_epochs * len(sentiment_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf179bdb-3c61-4819-8ead-dd84abf9a38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:18<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average loss: 0.03077170767458567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:17<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average loss: 0.022606948472888595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:18<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average loss: 0.021655397482186436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:19<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Average loss: 0.02075899245748558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:19<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Average loss: 0.020433013817392678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert to PyTorch datasets\n",
    "train_dataset = sentiment_dataset[\"test\"]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i in tqdm(range(0, len(train_dataset), batch_size)):\n",
    "        batch = train_dataset[i:i+batch_size]\n",
    "        inputs = tokenizer(batch[\"text\"], return_tensors=\"pt\",\n",
    "                           truncation=True, padding = True, max_length = max_len).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs)[\"logits\"][:, -1, :]#.cpu()\n",
    "        y = torch.LongTensor(batch[\"sentiment\"]).to(device) // 4\n",
    "        loss = torch.nn.functional.cross_entropy(outputs, y)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    "        _ = gc.collect()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Average loss: {total_loss / len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b53c557-1ef3-4df2-9b83-7df993109209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on Sentiment140...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Accuracy: 0.9971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating on Sentiment140...\")\n",
    "sentiment_accuracy = evaluate_sentiment(model, tokenizer, sentiment_dataset, device)\n",
    "print(f\"Sentiment Accuracy: {sentiment_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "757744cd-920b-4938-91cc-b4eca30b713f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1280, out_features=3, bias=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_head = model.lm_head\n",
    "sentiment_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c97bd5a-b07d-4a9e-8660-262251e7d047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on MRPC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 408/408 [02:03<00:00,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRPC Accuracy: 0.7059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.lm_head = mrpc_head\n",
    "print(\"Evaluating on MRPC...\")\n",
    "mrpc_accuracy = evaluate_mrpc(model, tokenizer, mrpc_dataset, device)\n",
    "print(f\"MRPC Accuracy: {mrpc_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b309bf5e-47c1-4499-a937-d49e412e325b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on SST-2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 872/872 [04:24<00:00,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST-2 Accuracy: 0.7603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.lm_head = sst_head\n",
    "print(\"Evaluating on SST-2...\")\n",
    "accuracy = evaluate_sst2(model, tokenizer, sst_dataset, device)\n",
    "print(f\"SST-2 Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6dd8263-ad4d-4be4-ba31-320dc0d7ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd526ab8-2822-41d3-b576-2c67b64d4633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 28.24\n"
     ]
    }
   ],
   "source": [
    "model.lm_head = lm_head\n",
    "ppl = calculate_perplexity(model, tokenizer, txt)\n",
    "print(\"Perplexity:\", round(ppl, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dd1ce73-e35f-4013-bd43-f93ffe1ee98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "every effort moves you forward,\" he said.\n",
      "\n",
      "\"I'm not going to be a politician. I'm not going to be a politician who's going to be in the media and say, 'I'm going to do this and I'm going to do that.' I'm going to do it the right way. I'm going to do it the right way.\"\n",
      "\n",
      "The mayor said he's not going to be a politician who's going to be in the media and say, 'I'm going to do this and I'm going to do that.' I'm going to do it the right way. - Mayor Rob Ford\n",
      "\n",
      "Ford said he's not going to be a politician who's going to be in the media and say, \"I'm going to do this and I'm going to do that.\"\n",
      "\n",
      "\"I'm not going to be a politician who's going to be in the media and say, 'I'm going to do this and I'm going to do that.' I'm going to do it the right way,\" he said.\n",
      "\n",
      "\"I'm not going to be a politician who's going to be in the media and say, 'I'm going to do this and I'm going to do that.' I'm going to do it the right way.\"\n",
      "\n",
      "Ford said he's not going to be a politician who's going to be in the media and say, \"I'm going to do this and I'm going to do that.\" I'm going to do it the right way. - Mayor Rob Ford\n",
      "\n",
      "Ford said he's not going to be a politician who's going to be in the media and say, \"I'm going to do this and I'm going to do that.\" I'm going to do it the right way. - Mayor Rob Ford\n",
      "\n",
      "Ford said he's not going to be a politician who's going to be in the media and say, \"I'm going to do this and I'm going to do that.\" I'm going to do it the right way. - Mayor Rob Ford\n",
      "\n",
      "Ford said he's not going to be a politician who's going to be in the media and say, \"I'm going to do this and I'm going to do that.\" I'm going to do it the right way. - Mayor Rob Ford\n",
      "\n",
      "Ford said he's not going to be a politician who's going to be in the media and say, \"I'm going to do\n"
     ]
    }
   ],
   "source": [
    "text = \"every effort moves you\"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(0)\n",
    "\n",
    "output = model.generate(input_ids, do_sample=False, max_length=500)\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af17c6c1-7429-4e42-8875-ee81b19e5d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214fd1d3-f34a-4d06-af6f-a5c342d2fe69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
