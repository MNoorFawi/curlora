{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e22781c-c04f-49df-8ef2-5f0f835948b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "import os\n",
    "#os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72f97992-0e62-44c2-8fea-5141255b90b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters after: 1,474,560\n",
      "Perplexity: 28.25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1280)\n",
       "    (wpe): Embedding(1024, 1280)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-35): 36 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): LinearWithLoRA(\n",
       "            (linear): Conv1D()\n",
       "            (lora): LoRALayer()\n",
       "          )\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1280, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AdamW, get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "import gc\n",
    "\n",
    "model_name = \"gpt2-large\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "ltype = \"lora\"\n",
    "for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, type(model.transformer.h[0].attn)):\n",
    "        if ltype == \"lora\":\n",
    "            module.c_attn = LinearWithLoRA(module.c_attn, 8, 1)\n",
    "        else:\n",
    "            module.c_attn = LinearWithCURLoRA(module.c_attn, 8, 1)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters after: {total_params:,}\")\n",
    "\n",
    "model.to(device)\n",
    "    \n",
    "ppl = calculate_perplexity(model, tokenizer, txt)\n",
    "print(\"Perplexity:\", round(ppl, 2))\n",
    "    \n",
    "torch.manual_seed(1311)\n",
    "num_classes = 2\n",
    "lm_head = model.lm_head\n",
    "in_features=1280\n",
    "    \n",
    "model.lm_head = torch.nn.Linear(in_features=in_features, out_features=num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0906f755-0380-4e60-83d0-6a6f5d5ab417",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cd7e4c0-43fa-4123-b371-b85904b1a4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set up optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(mrpc_dataset[\"train\"])\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=500, num_training_steps=num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32081eca-9f8c-4414-97b2-e71da75ef4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [03:04<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average loss: 0.019906573972564227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [03:10<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average loss: 0.01902800353168791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [03:08<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average loss: 0.01624104251420875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = mrpc_dataset[\"train\"]\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i in tqdm(range(0, len(train_dataset), batch_size)):\n",
    "        batch = train_dataset[i:i+batch_size]\n",
    "        inputs = tokenizer(batch[\"sentence1\"], batch[\"sentence2\"], return_tensors=\"pt\",\n",
    "                           truncation=True, padding = True, max_length = max_len).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs)[\"logits\"][:, -1, :]#.cpu()\n",
    "        y = torch.LongTensor(batch[\"label\"]).to(device)\n",
    "        loss = torch.nn.functional.cross_entropy(outputs, y)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        torch.cuda.empty_cache()\n",
    "        _ = gc.collect()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Average loss: {total_loss / len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84ce9d9c-9368-4e2a-b898-7c263541f7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on MRPC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 408/408 [00:09<00:00, 41.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRPC Accuracy: 0.7917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating on MRPC...\")\n",
    "mrpc_accuracy = evaluate_mrpc(model, tokenizer, mrpc_dataset, device)\n",
    "print(f\"MRPC Accuracy: {mrpc_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efdd8bfe-00f9-4ac3-bfa1-8b86a8ec5540",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrpc_head = model.lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db4ae15-8b50-4fb3-90a9-af2274771d13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "626155e0-dfd7-4623-87c9-804d295c0c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1311)\n",
    "\n",
    "num_classes = 2\n",
    "model.lm_head = torch.nn.Linear(in_features=in_features, out_features=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "590cd2ae-4788-47d4-bdf7-b53af4a6908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(sst_dataset[\"train\"])\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=500, num_training_steps=num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfd3d57c-48e7-41b8-a143-9a7fd31977d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [02:43<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average loss: 0.001606773968788933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [02:00<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average loss: 0.0007389305756085664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [02:43<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average loss: 0.0005056121178319505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert to PyTorch datasets\n",
    "train_dataset = sst_dataset[\"train\"]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i in tqdm(range(0, 5000, batch_size)):\n",
    "        batch = train_dataset[i:i+batch_size]\n",
    "        inputs = tokenizer(batch[\"sentence\"], return_tensors=\"pt\",\n",
    "                           truncation=True, padding = True, max_length = max_len).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs)[\"logits\"][:, -1, :]#.cpu()\n",
    "        y = torch.LongTensor(batch[\"label\"]).to(device)\n",
    "        loss = torch.nn.functional.cross_entropy(outputs, y)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        torch.cuda.empty_cache()\n",
    "        _ = gc.collect()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Average loss: {total_loss / len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2523032d-dbb9-4152-a3b7-3abc878c518e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on SST-2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 872/872 [00:17<00:00, 49.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST-2 Accuracy: 0.9369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating on SST-2...\")\n",
    "accuracy = evaluate_sst2(model, tokenizer, sst_dataset, device)\n",
    "print(f\"SST-2 Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5a59825-5542-4cc0-99dc-f8caed532280",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a2f0246-fbaa-4985-bbd1-9068e7d9db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_head = model.lm_head\n",
    "model.lm_head = mrpc_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62b0d326-74f3-4875-81b2-aee6b40f166a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on MRPC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 408/408 [00:08<00:00, 50.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRPC Accuracy: 0.7647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating on MRPC...\")\n",
    "mrpc_accuracy = evaluate_mrpc(model, tokenizer, mrpc_dataset, device)\n",
    "print(f\"MRPC Accuracy: {mrpc_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fb8b486-8461-4fc9-8451-09f841e9e602",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1311)\n",
    "\n",
    "num_classes = 3\n",
    "model.lm_head = torch.nn.Linear(in_features=in_features, out_features=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c26694b-61c8-425f-9363-fd4f83a8f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "num_epochs = 5\n",
    "num_training_steps = num_epochs * len(sentiment_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf179bdb-3c61-4819-8ead-dd84abf9a38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:17<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average loss: 0.018428838695866995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:18<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average loss: 0.00886059582353117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:19<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average loss: 0.005677207840614051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:18<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Average loss: 0.0038867912977096067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:17<00:00,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Average loss: 0.0031792531912046744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = sentiment_dataset[\"test\"]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i in tqdm(range(0, len(train_dataset), batch_size)):\n",
    "        batch = train_dataset[i:i+batch_size]\n",
    "        inputs = tokenizer(batch[\"text\"], return_tensors=\"pt\",\n",
    "                           truncation=True, padding = True, max_length = max_len).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs)[\"logits\"][:, -1, :]#.cpu()\n",
    "        y = torch.LongTensor(batch[\"sentiment\"]).to(device) // 4\n",
    "        loss = torch.nn.functional.cross_entropy(outputs, y)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    "        _ = gc.collect()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Average loss: {total_loss / len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b53c557-1ef3-4df2-9b83-7df993109209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on Sentiment140...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:07<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Accuracy: 0.9229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating on Sentiment140...\")\n",
    "sentiment_accuracy = evaluate_sentiment(model, tokenizer, sentiment_dataset, device)\n",
    "print(f\"Sentiment Accuracy: {sentiment_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "757744cd-920b-4938-91cc-b4eca30b713f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1280, out_features=3, bias=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_head = model.lm_head\n",
    "sentiment_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c97bd5a-b07d-4a9e-8660-262251e7d047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on MRPC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 408/408 [00:09<00:00, 44.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRPC Accuracy: 0.4877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.lm_head = mrpc_head\n",
    "print(\"Evaluating on MRPC...\")\n",
    "mrpc_accuracy = evaluate_mrpc(model, tokenizer, mrpc_dataset, device)\n",
    "print(f\"MRPC Accuracy: {mrpc_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b309bf5e-47c1-4499-a937-d49e412e325b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on SST-2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 872/872 [00:18<00:00, 45.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST-2 Accuracy: 0.8979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.lm_head = sst_head\n",
    "print(\"Evaluating on SST-2...\")\n",
    "accuracy = evaluate_sst2(model, tokenizer, sst_dataset, device)\n",
    "print(f\"SST-2 Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6dd8263-ad4d-4be4-ba31-320dc0d7ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd526ab8-2822-41d3-b576-2c67b64d4633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 42.96\n"
     ]
    }
   ],
   "source": [
    "model.lm_head = lm_head\n",
    "ppl = calculate_perplexity(model, tokenizer, txt)\n",
    "print(\"Perplexity:\", round(ppl, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dd1ce73-e35f-4013-bd43-f93ffe1ee98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "every effort moves you closer to the story and the characters, and the beautiful landscapes, and the wonderful music, by the author, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by the composer, and by the wonderful music by\n"
     ]
    }
   ],
   "source": [
    "text = \"every effort moves you\"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(0)\n",
    "\n",
    "output = model.generate(input_ids, do_sample=False, max_length=500)\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af17c6c1-7429-4e42-8875-ee81b19e5d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb4c3d3-360f-4c52-ad9f-da7b76dcd3e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
